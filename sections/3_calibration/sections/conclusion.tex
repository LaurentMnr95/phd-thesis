\section{Conclusion}
In this paper, we set some solid theoretical foundations for the study of adversarial consistency. We highlighted the importance of the definition of the $0/1$ loss, as well as the nuance between calibration and consistency that is specific to the adversarial setting.

Furthermore, we solved the calibration problem, by giving a necessary and sufficient condition for decreasing, continuous margin losses to be adversarially calibrated. Since this is a necessary condition for consistency, an important consequence of this result is that no convex margin loss can be consistent. This rules out most of the commonly used surrogates, and spurs the need for new families of consistent, yet easily optimisable families of losses.

We provide a first insights into which losses may be consistent, by showing that translations of odd loss functions are calibrated.