
\section{The Adversarial Attack Problem}
\label{sec:adv-problem}
\subsection{A Motivating Example}
\label{sec:motiv-ex}

\begin{figure*}[!ht]
    \centering
\includegraphics[width=\textwidth]{Images/Drawing-Intro-Mixte-Nash-on-a-line.pdf}   \caption{Motivating example: blue distribution represents label $-1$ and the red one, label $+1$.  The height of columns represents their mass. The red and blue arrows represent the attack on the given classifier. On left: deterministic classifiers ($f_1$ on the left, $f_2$ in the middle) for whose, the blue point can always be attacked. On right: a randomized classifier, where the attacker has a probability $1/2$ of failing, regardless of the attack it selects. }
    \label{fig:motivating_ex}
\end{figure*}
Consider the binary classification task illustrated in Figure~\ref{fig:motivating_ex}. We assume that all input-output pairs $(X,Y)$ are sampled from a distribution $\PP$ defined as follows
$$ 
\PP\left(Y =\pm 1\right)=1/2 \ \mbox{ and }\left\{
    \begin{array}{ll}
        \PP\left(X=0 \mid Y=-1\right) = 1 \\
        \PP\left(X= \pm 1 \mid Y=1\right) = 1/2 
    \end{array}
\right.
$$ 
Given access to $\PP$, the adversary aims to maximize the expected risk, but can only move each point by at most $1$ on the real line. In this context, we study two classifiers: $f_1(x) = -x -1/2$ and $f_2(x)=x-1/2$\footnote{$(X,Y) \sim \PP$ is misclassified by $f_i$ if and only if $f_i(X)Y \leq 0$}. Both $f_1$ and $f_2$ have a standard risk of $1/4$. In the presence of an adversary, the risk (\emph{a.k.a.} the adversarial risk) increases to $1$. Here, using a randomized classifier can make the system more robust. Consider $f$ where $f=f_1$ w.p. $1/2$ and $f_2$ otherwise. The standard risk of $f$ remains $1/4$ but its adversarial risk is $3/4<1$. Indeed, when attacking $f$, any adversary will have to choose between moving points from $0$ to $1$ or to $-1$. Either way, the attack only works half of the time; hence an overall adversarial risk of $3/4$. Furthermore, if $f$ knows the strategy the adversary uses, it can always update the probability it gives to $f_1$ and $f_2$ to get a better (possibly deterministic) defense. For example, if the adversary chooses to always move $0$ to $1$, the classifier can set $f=f_1$ w.p. $1$ to retrieve an adversarial risk of $1/2$ instead of $3/4$. %In other words, if the adversary can only use a deterministic attack, then there exists no equilibrium in the game.

Now, what happens if the adversary can use randomized strategies, meaning that for each point it can flip a coin before deciding where to move? In this case, the adversary could decide to move points from $0$ to $1$ w.p. $1/2$ and to $-1$ otherwise. This strategy is still optimal with an adversarial risk of $3/4$ but now the classifier cannot use its knowledge of the adversary's strategy to lower the risk. We are in a state where neither the adversary nor the classifier can benefit from unilaterally changing its strategy. In the game theory terminology, this state is called a Mixed Nash equilibrium. %Previous works studying adversarial examples from the scope of game theory investigated the existence of Mixed Nash equilibria in restricted settings where the adversary can by reduced to a set of parameters~\citep{7533509,DBLP:journals/corr/abs-1906-02816,bose2021adversarial}. But, as pointed out in \citep{pinot2020randomization} and \citep{pydi2019adversarial}, studying the existence of a Mixed Nash equilibrium in a more general framework is a challenging open problem. In the present paper we tackle the following question.

\subsection{General setting}
Let us consider a loss function: $\loss:\Theta\times (\XX\times\YY)\to [0,\infty)$ satisfying the following set of assumptions.
\begin{assump}[Loss function]
\label{ass:loss}
1) The loss function $\loss$ is a non negative Borel measurable function. 2) For all $\theta\in\Theta$, $\loss(\theta,\cdot)$ is upper-semi continuous. 3) There exists $M>0$ such that for all $\theta\in\Theta$, $(x,y)\in\XX\times\YY$, $0\leq \loss(\theta,(x,y))\leq M$.
\end{assump}
It is usual to assume upper-semi continuity when studying optimization over distributions~\citep{villani2003topics,blanchet2019quantifying}. Furthermore, considering bounded (and positive) loss functions is also very common in learning theory~\citep{bartlett2002rademacher} and is not restrictive. 

In the adversarial examples framework, the loss of interest is the $0/1$ loss, for whose surrogates are misunderstood  and is the object of Chapter~\ref{chap:calibration}; hence it is essential that a $0/1$ loss satisfies Assumption~\ref{ass:loss}. In the binary classification setting (\emph{i.e.} $\YY=\{-1,+1\}$) a possible $0/1$ loss writes $\loss_{0/1}(\theta,(x,y)) = \mathbf{1}_{yf_\theta(x)\leq 0}$. Then, assuming that for all $\theta$, $f_\theta(\cdot)$ is continuous and for all $x$, $f_\cdot(x)$ is continuous, the $0/1$ loss satisfies Assumption~\ref{ass:loss}. In particular, it is the case for neural networks with continuous activation functions.


\subsection{Measure Theoretic Lemmas}

We first recall and prove some important lemmas about theoretic measure.
\begin{lemma}[Fubini's theorem]
\label{lem:fubini}
Let $l:\Theta\times(\XX\times\YY)\rightarrow [0,\infty)$ satisfying Assumption~\ref{ass:loss}. Then for all $\mu\in\mathcal{M}^1_+(\Theta)$, $\int \loss(\theta,\cdot)d\mu(\theta)$ is Borel measurable; for  $\QQ\in\mathcal{M}^1_+(\XX\times\YY)$, $\int \loss(\cdot,(x,y))d\QQ(x,y)$ is Borel measurable. Moreover: $\int \loss(\theta,(x,y))d\mu(\theta)d\QQ(x,y)=\int \loss(\theta,(x,y))d\QQ(x,y)d\mu(\theta)$
\end{lemma}

\begin{lemma}
\label{lem:usc1}
Let $\loss:\Theta\times(\XX\times\YY)\rightarrow [0,\infty)$ satisfying Assumption~\ref{ass:loss}.
Then for all $\mu\in\mathcal{M}^1_+(\Theta)$, $(x,y)\mapsto\int \loss(\theta,(x,y))d\mu(\theta)$ is upper semi-continuous and hence Borel measurable.  
\end{lemma}
\begin{proof}
Let $(x_n,y_n)_n$ be a sequence of $\XX\times\YY$ converging to $(x,y)\in\XX\times\YY$.  For all $\theta\in\Theta$, $M-\loss(\theta,\cdot)$ is non negative and lower semi-continuous. Then by Fatou's Lemma applied:
\begin{align*}
   \int M-\loss(\theta,(x,y))d\mu(\theta)&\leq\int \liminf_{n\to\infty}  M-\loss(\theta,(x_n,y_n))d\mu(\theta)\\
   &\leq  \liminf_{n\to\infty}  \int M-\loss(\theta,(x_n,y_n))d\mu(\theta) 
\end{align*}

Then we deduce that: $\int M- \loss(\theta,\cdot)d\mu(\theta)$ is lower semi-continuous and then $\int \loss(\theta,\cdot)d\mu(\theta)$ is upper-semi continuous.
\end{proof}


\begin{lemma}
\label{lem:usc2}

Let $\loss:\Theta\times(\XX\times\YY)\rightarrow [0,\infty)$ satisfying Assumption~\ref{ass:loss}
Then for all $\mu\in\mathcal{M}^1_+(\Theta)$, $\QQ\mapsto\int \loss(\theta,(x,y))d\mu(\theta)d\QQ(x,y)$ is upper semi-continuous for weak topology of measures. 
\end{lemma}
\begin{proof}
 $-\int \loss(\theta,\cdot)d\mu(\theta) $ is lower semi-continuous from Lemma~\ref{lem:usc1}. Then $M-\int \loss(\theta,\cdot)d\mu(\theta) $ is lower semi-continuous and non negative. Let denote $v$ this function. Let $(v_n)_n$ be a non-decreasing sequence of continuous bounded functions such that $v_n\to v$. Let $(\QQ_k)_k$ converging weakly towards $\QQ$. Then by monotone convergence:
 
 \begin{align*}
     \int vd\QQ = \lim_n \int v_nd\QQ =\lim_n \lim_k\int v_nd\QQ_k\leq \liminf_k \int vd\QQ_k
 \end{align*}
 Then $\QQ\mapsto\int vd\QQ$ is lower semi-continuous and then $\QQ\mapsto\int \loss(\theta,(x,y))d\mu(\theta)d\QQ(x,y)$ is upper semi-continuous for weak topology of measures. 
 \end{proof}



\begin{lemma}
\label{lem:measure-sup}
Let $\loss:\Theta\times(\XX\times\YY)\rightarrow [0,\infty)$ satisfying Assumption~\ref{ass:loss}.
Then for all $\mu\in\mathcal{M}^1_+(\Theta)$, $(x,y)\mapsto \sup_{(x',y'),d(x,x')\leq\varepsilon,y=y'} \int \loss(\theta,(x',y'))d\mu(\theta)$ is universally measurable (i.e. measurable for all Borel probability measures). And hence the adversarial risk is well defined. 
\end{lemma}
\begin{proof}
Let $\phi :(x,y)\mapsto \sup_{(x',y'),d(x,x')\leq\varepsilon,y=y'} \int \loss(\theta,(x',y'))d\mu(\theta)$. Then for $u\in\bar{\mathbb{R}}$:
\begin{align*}
\left\{\phi(x,y)>u\right\}=\text{Proj}_1\left\{((x,y),(x',y'))\mid\int \loss(\theta,(x',y'))d\mu(\theta)-c_\varepsilon((x,y),(x',y'))>u\right\}
\end{align*}
By Lemma~\ref{lem:usc2}: $((x,y),(x',y'))\mapsto \int \loss(\theta,(x',y'))d\mu(\theta)-c_\varepsilon((x,y),(x',y'))$ is upper-semicontinuous hence Borel measurable. So its level sets are Borel sets, and by~\citep[Proposition 7.39]{bertsekas2004stochastic}, the projection of a Borel set is analytic. And then $\left\{\phi(x,y)>u\right\}$ universally measurable thanks to~\citep[Corollary 7.42.1]{bertsekas2004stochastic}. We deduce that $\phi$ is universally measurable.
\end{proof}



\subsection{Adversarial Risk Minimization}
The standard risk for a single classifier $\theta$ associated with the loss $\loss$ satisfying Assumption~\ref{ass:loss} writes: $\risk(\theta):=\mathbb{E}_{(x,y)\sim \PP}\left[\loss(\theta,(x,y))\right]$. Similarly, the adversarial risk of $\theta$ at level $\varepsilon$ associated with the loss $\loss$ is defined as\footnote{For the well-posedness, see Lemma~\ref{lem:measure-sup}.}
\begin{align*}
    \risk_\varepsilon(\theta):=\mathbb{E}_{(x,y)\sim \PP}\left[\sup_{x'\in\XX,~d(x,x')\leq\varepsilon}\loss(\theta,(x',y))\right].
\end{align*}
 It is clear that $\risk_0(\theta) =\risk(\theta)$ for all $\theta$. We can generalize these notions with distributions of classifiers. In other terms the classifier is then randomized according to some distribution $\mu\in\mathcal{M}^1_+(\Theta)$. A classifier is randomized if for a given input, the output of the classifier is a probability distribution.
 The standard risk of a randomized classifier $\mu$ writes $\risk(\mu) = \mathbb{E}_{\theta\sim\mu}\left[\risk (\theta)\right]$. Similarly, the adversarial risk of the randomized classifier $\mu$ at level $\varepsilon$ is\footnote{This risk is also well posed (see Lemma~\ref{lem:measure-sup}).}
\begin{align*}
    \risk_\varepsilon(\mu):=\mathbb{E}_{(x,y)\sim \PP}\left[\sup_{x'\in\XX,~d(x,x')\leq\varepsilon}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x',y))\right]\right].
\end{align*}
For instance, for the $0/1$ loss, the inner maximization problem, consists in maximizing the probability of misclassification for a given couple $(x,y)$. Note that $\risk(\delta_\theta)=\risk(\theta)$ and $\risk_\varepsilon(\delta_\theta)=\risk_\varepsilon(\theta)$. In the remainder of this section, we study the adversarial risk minimization problems with randomized and deterministic classifiers and denote
\begin{align}
\label{eq:advriskmin}
    \valuerand_\varepsilon:=\inf_{\mu\in\mathcal{M}^1_+(\Theta)} \risk_\varepsilon(\mu),~\valuedet_\varepsilon:=\inf_{\theta\in\Theta} \risk_\varepsilon(\theta)
\end{align}
Note that we can show that the standard risk infima are equal :  $\valuerand_0=\valuedet_0$. 
\begin{prop}
\label{prop:eqstandardrisk}
Let $\PP$ be a Borel probability distribution on $\XX\times\YY$, and $l$ a loss satisfying Assumption~\ref{ass:loss}, then:
\begin{align*}
        \inf_{\mu\in\mathcal{M}^1_+(\Theta)} \risk(\mu) =\inf_{\theta\in\Theta} \risk(\theta)
\end{align*}
\end{prop}
\begin{proof}
It is clear that:         $\inf_{\mu\in\mathcal{M}^1_+(\Theta)} \risk(\mu) \leq \inf_{\theta\in\Theta} \risk(\theta)$. Now, let $\mu\in\mathcal{M}^1_+(\Theta)$, then:
\begin{align*}
    \risk(\mu)= \mathbb{E}_{\theta\sim\mu}(\risk(\theta))&\geq \essinf_\mu \mathbb{E}_{\theta\sim\mu} \left(\risk(\theta)\right)\\
    &\geq\inf_{\theta\in\Theta} \risk(\theta).
\end{align*}
where $\essinf$ denotes the essential infimum.
\end{proof}
\begin{rmq}
No randomization is needed for minimizing the standard risk. Denoting $\mathcal{V}$ this common value, we also have the following inequalities for any $\varepsilon>0$, $\mathcal{V}\leq \valuerand_\varepsilon\leq \valuedet_\varepsilon$.
\end{rmq}



\subsection{Distributional Formulation of the Adversarial Risk} 

To account for the possible randomness of the adversary, we rewrite the adversarial attack problem as a convex optimization problem over distributions. Let us first introduce the set of adversarial distributions.
\begin{definition}[Set of adversarial distributions]
Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\varepsilon>0$. We define the set of adversarial distributions as
\begin{align*}
\mathcal{A}_{\varepsilon}&(\PP) := \left\{\QQ\in\mathcal{M}^+_1(\XX\times\YY)\mid\exists \gamma\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right),\right.\\
&\left.d(x,x')\leq\varepsilon,~y=y'~~ \gamma\text{-a.s.},~\Pi_{1\sharp}\gamma=\PP,~\Pi_{2\sharp}\gamma=\QQ\right\} 
\end{align*}
where $\Pi_i$ denotes the projection on the $i$-th component, and $g_\sharp$ the push-forward measure by a measurable function $g$.
\end{definition}
An attacker that can move the initial distribution $\PP$ anywhere in $\mathcal{A}_\varepsilon(\PP)$ is not applying a point-wise deterministic perturbation as considered in the standard adversarial risk. %For every point $(x,y)$ in the support of $\PP$, the attacker is allowed to move $(x,y)$ according to a ``random mapping'' in the ball of radius $\varepsilon$, and not to a single other point $(x',y)$ like the usual attacker in adversarial attacks. 
In other words, for a point $(x,y)\sim\PP$, the attacker could choose a distribution $q(\cdot\mid(x,y))$ whose support is included in $\{(x',y')\mid d(x,x')\leq \epsilon,~y=y'\}$ from which he will sample the adversarial attack. In this sense, we say the attacker is allowed to be randomized.
% This set allows to move every single point in the support of $\PP$ and moving its mass everywhere as far as the perturbation is smaller than $\varepsilon$ and does not change the `true' label. In this problem, the attacker can then play randomized strategies to move the samples inside the balls of radius $\varepsilon$. \textcolor{red}{Pas hyper limpide je trouve}

\textbf{Link with DRO.} We immediately remark that $\mathcal{A}_\varepsilon(\PP)$ correspond in the Wasserstein-$\infty$ set associated with
the cost
\begin{align*}
    d'((x,y),(x',y'))\mapsto \left\{
        \begin{array}{ll}
            d(x,x') & \mbox{if } y = y'\\
            +\infty & \mbox{otherwise.}
        \end{array}
    \right.
\end{align*}
We also remark, such a set can be defined from usual (not $\infty$) Wasserstein uncertainty sets:  for an arbitrary $\varepsilon>0$, we define the cost $c_\varepsilon$ as follows
\begin{align*}
c_\varepsilon((x,y),(x',y')) := \left\{
    \begin{array}{ll}
        0 & \mbox{if } d(x,x')\leq\varepsilon\mbox{ and }y = y'\\
        +\infty & \mbox{otherwise.}
    \end{array}
\right.
\end{align*}
This cost is lower semi-continuous and penalizes to infinity perturbations that change the label or move the input by a distance greater than $\varepsilon$. As Proposition~\ref{prop:wass_ball} shows, the Wasserstein ball associated with $c_\varepsilon$ is equal to $\mathcal{A}_{\varepsilon}(\PP)$.
\begin{prop}
\label{prop:wass_ball}
Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\varepsilon>0$ and $\eta\geq 0$, then
    $\mathcal{B}_{c_\varepsilon}(\PP,\eta) =\mathcal{A}_{\varepsilon}(\PP)$.
Moreover, $\mathcal{A}_{\varepsilon}(\PP)$ is convex and compact for the weak topology of $\mathcal{M}^+_1(\XX\times\YY)$.
\end{prop}
\begin{proof}
Let $\eta>0$. Let $\QQ\in\mathcal{A}_\varepsilon(\PP)$. There exists $\gamma\in
\mathcal{M}^+_1\left((\XX\times\YY)^2\right)$ such that, $d(x,x')\leq\varepsilon$, $y=y'$ $\gamma$-almost surely, and $\Pi_{1\sharp}\gamma=\PP$, and $\Pi_{2\sharp}\gamma=\QQ$. Then $\int c_\varepsilon d \gamma = 0\leq \eta$. Then, we deduce that $W_{c_\varepsilon}(\PP,\QQ)\leq \eta$, and $\QQ\in\mathcal{B}_{c_\varepsilon}(\PP,\eta)$. Reciprocally, let $\QQ\in\mathcal{B}_{c_\varepsilon}(\PP,\eta)$. Then, since the infimum is attained in the Wasserstein definition, there exists $\gamma\in
\mathcal{M}^+_1\left((\XX\times\YY)^2\right)$ such that $\int c_\varepsilon d \gamma \leq \eta$. Since $c_\varepsilon((x,x'),(y,y'))=+\infty$ when $d(x,x')>\varepsilon$ and $y\neq y'$, we deduce that, $d(x,x')\leq\varepsilon$ and $y=y'$, $\gamma$-almost surely. Then $\QQ\in\mathcal{A}_\varepsilon(\PP)$. We have then shown that: $\mathcal{A}_\varepsilon(\PP)=\mathcal{B}_{c_\varepsilon}(\PP,\eta)$.

The convexity of $\mathcal{A}_\varepsilon(\PP)$ is then immediate from the relation with the Wasserstein uncertainty set.

Let us show first that $\mathcal{A}_\varepsilon(\PP)$ is relatively compact for weak topology. To do so we will show that $\mathcal{A}_\varepsilon(\PP)$ is tight and apply Prokhorov's theorem. Let $\delta>0$, $(\XX\times \YY,d\oplus d')$ being a Polish space, $\{\PP\}$ is tight then there exists $K_\delta$ compact such that $\PP(K_\delta)\geq1-\delta$.
Let $\Tilde{K}_\delta:=\left\{(x',y')\mid \exists (x,y)\in K_\delta,~ d(x',x)\leq\varepsilon,~y=y'\right\}$.  Recalling that $(\XX,d)$ is proper (i.e. the closed balls are compact), so $\Tilde{K}_\delta$ is compact. Moreover for $\QQ\in\mathcal{A}_\varepsilon(\PP)$, $\QQ(\Tilde{K}_\delta)\geq \PP(K_\delta)\geq 1-\delta$. And then, Prokhorov's theorem holds, and $\mathcal{A}_\varepsilon(\PP)$ is relatively compact for weak topology.

Let us now prove that $\mathcal{A}_\varepsilon(\PP)$ is closed to conclude.  Let $(\QQ_n)_n$ be a sequence of $\mathcal{A}_\varepsilon(\PP)$ converging towards some $\QQ$ for weak topology. For each $n$, there exists $\gamma_n\in \mathcal{M}^1_+(\XX\times\YY)$ such that $d(x,x')\leq\varepsilon$ and $y=y'$ $\gamma_n$-almost surely and $\Pi_{1\sharp}\gamma_n=\PP$, $\Pi_{2\sharp}\gamma_n=\QQ_n$. $\{\QQ_n,n\geq0\}$ is relatively compact, then tight, then $\bigcup_n \Gamma_{\PP,\QQ_n}$ is tight, then relatively compact by Prokhorov's theorem. $(\gamma_n)_n\in\bigcup_n \Gamma_{\PP,\QQ_n}$, then up to an extraction,  $\gamma_n\to\gamma$. Then $d(x,x')\leq\varepsilon$ and $y=y'$ $\gamma$-almost surely, and by continuity, $\Pi_{1\sharp}\gamma=\PP$ and by continuity, $\Pi_{2\sharp}\gamma=\QQ$. And hence $\mathcal{A}_\varepsilon(\PP)$ is closed.

Finally $\mathcal{A}_\varepsilon(\PP)$ is a convex compact set for the weak topology. 
\end{proof}




% Next proposition shows that the set $\mathcal{A}_{\varepsilon}(\PP)$ satisfies interesting topological properties. See proof in Appendix~\ref{prv:a_eps}.
% \begin{prop}
% \label{prop:a_eps}
% Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\varepsilon>0$. $\mathcal{A}_{\varepsilon}(\PP)$ is convex and compact for the weak topology of $\mathcal{M}^+_1(\XX\times\YY)$.
% \end{prop}
Thanks to this result, we can reformulate the adversarial risk as the value of a convex problem over $\mathcal{A}_\varepsilon(\PP)$. %See proof in Appendix~\ref{prv:duality-rand}.
\begin{prop} 
\label{prop:dro_adv}
Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\mu$ a Borel probability distribution on $\Theta$. Let $\loss:\Theta\times(\XX\times\YY)\to [0,\infty)$ satisfying Assumption~\ref{ass:loss}. Let $\varepsilon>0$. Then:
\begin{align}
\label{eq:dro-adv}
\risk_\varepsilon(\mu)= \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x',y')\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x',y'))\right].
\end{align}
The supremum is attained. Moreover $\QQ^*\in \mathcal{A}_{\varepsilon}(\PP)$ is an optimum of Problem~\eqref{eq:dro-adv} if and only if there exists $\gamma^*\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right)$ such that: $\Pi_{1\sharp}\gamma^*=\PP$, $\Pi_{2\sharp}\gamma^*=\QQ^*$, $d(x,x')\leq\varepsilon$, $y=y'$ and  $\loss(x',y')=\sup_{\substack{u\in\XX,d(x,u)\leq\varepsilon}}\loss(u,y)$ $\gamma^*$-almost surely.
\end{prop}

\begin{proof}
Let $\mu\in\mathcal{M}^1_+(\Theta)$. Let $\Tilde{f}:((x,y),(x',y'))\mapsto \mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x,y))\right]-c_\varepsilon((x,y),(x',y'))$. $\Tilde{f}$ is upper-semi continuous, hence upper semi-analytic. Then, by upper semi continuity of $\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,\cdot)\right]$ on the compact $\{(x',y')\mid~d(x,x')\leq\varepsilon,y=y'\}$ and~\citep[Proposition 7.50]{bertsekas2004stochastic}, there exists a universally measurable mapping $T$ such that $\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,T(x,y))\right]=\sup_{(x',y'),~d(x,x')\leq\varepsilon,y=y'}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x,y))\right]$.  Let $\QQ = T_{\sharp}\PP$, then $\QQ\in\mathcal{A}_\varepsilon(\PP)$. And then $$\mathbb{E}_{(x,y)\sim\PP}\left[\sup_{(x',y'),~d(x,x')\leq\varepsilon,y=y'}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x',y'))\right]\right]\leq \sup_{\QQ\in\mathcal{A}_\varepsilon(\PP)}\mathbb{E}_{(x,y)\sim\QQ}\left[\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x,y))\right]\right]$$.

Reciprocally, let $\QQ\in\mathcal{A}_\varepsilon(\PP)$. There exists $\gamma\in\mathcal{M}^1_+((\XX\times\YY)^2)$, such that $d(x,x')\leq\varepsilon$ and $y=y'$ $\gamma$-almost surely, and, $\Pi_{1\sharp}\gamma=\PP$ and  $\Pi_{2\sharp}\gamma=\QQ$. Then:
$\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x',y'))\right]\leq\sup_{(u,v),~d(x,u)\leq\varepsilon,y=v}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(u,v))\right]$ $\gamma$-almost surely. Then, we deduce that:
\begin{align*}
    \mathbb{E}_{(x',y')\sim\QQ}\left[\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x',y'))\right]\right]& =     \mathbb{E}_{(x,y,x',y')\sim\gamma}\left[\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x',y'))\right]\right] \\
    &\leq\mathbb{E}_{(x,y,x',y')\sim\gamma}\left[\sup_{(u,v),~d(x,u)\leq\varepsilon,y=v}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(u,v))\right]\right]\\
    &\leq\mathbb{E}_{(x,y)\sim\PP}\left[\sup_{(u,v),~d(x,u)\leq\varepsilon,y=v}\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(u,v))\right]\right]
\end{align*}

Then we deduce the expected result:
\begin{align*}
\risk_\varepsilon(\mu)= \sup_{\QQ\in\mathcal{A}_\varepsilon(\PP)}\mathbb{E}_{(x,y)\sim\QQ}\left[\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x,y))\right]\right]
\end{align*}
Let us show that the optimum is attained. $\QQ\mapsto\mathbb{E}_{(x,y)\sim\QQ}\left[\mathbb{E}_{\theta\sim\mu}\left[\loss(\theta,(x,y))\right]\right]$ is upper semi continuous by Lemma~\ref{lem:usc2} for the weak topology of measures, and $\mathcal{A}_\varepsilon(\PP)$ is compact by Proposition~\ref{prop:wass_ball}, then by~\citep[Proposition 7.32]{bertsekas2004stochastic}, the supremum is attained for a certain $\QQ^*\in\mathcal{A}_\varepsilon(\PP)$. 

\end{proof}

The adversarial attack problem is a DRO problem for the cost $c_\varepsilon$.
Proposition~\ref{prop:dro_adv} means that, against a fixed classifier $\mu$, the randomized attacker that can move the distribution in $\mathcal{A}_\varepsilon(\PP)$ has exactly the same power as an attacker that moves every single point $x$ in the ball of radius $\varepsilon$.  By Proposition~\ref{prop:dro_adv}, we also  deduce that the adversarial risk can be casted as a linear optimization problem over distributions.

\begin{rmq}
  In a recent work,~\citep{pydi2019adversarial} proposed a similar adversary using Markov kernels but left as an open question the link with the classical adversarial risk, due to measurability issues. Proposition~\ref{prop:dro_adv} solves these issues. The result is similar to~\citep{blanchet2019quantifying}. Although we believe its proof might be extended for infinite valued costs,~\citep{blanchet2019quantifying} did not treat that case. We provide an alternative proof in this special case. 
\end{rmq}


 %In the next section we show how Proposition~\ref{prop:dro_adv} helps casting the adversarial risk minimization problem as a game between the classifier and the attacker for which we study the Nash equilibria.

% \paragraph{Link with distributionally robust optimization (DRO). } The optimization problem over $\mathcal{A}_\varepsilon(\PP)$ is very close to a DRO problem ~\citep{blanchet2019quantifying}. 
% When $(\mathcal{Z},d)$ a Polish space and $c:\mathcal{Z}^2\rightarrow\mathbb{R}^+\cup\{+\infty\}$ be a lower semi-continuous function, for $\PP,\QQ\in\mathcal{M}^+_1(\mathcal{Z})$ , the primal Optimal Transport problem is defined as:
% \begin{align*}
%   W_c(\PP,\QQ):=\inf_{\gamma\in\Gamma_{\PP,\QQ}}  \int_{\mathcal{Z}^2} c(z,z')d\gamma(z,z')
% \end{align*}
% with $\Gamma_{\PP,\QQ}:=\left\{\gamma\in\mathcal{M}^+_1(\mathcal{Z}^2)\mid~\Pi_{1\sharp}\gamma = \PP,~\Pi_{2\sharp}\gamma = \QQ \right\}$. When $\delta>0$ and for $\PP\in\mathcal{M}^+_1(\mathcal{Z})$, the associated Wasserstein uncertainty set is defined as: 
% \begin{align*}
%     \mathcal{B}_{c}(\PP,\delta) := \left\{\QQ\in \mathcal{M}^+_1(\mathcal{Z})\mid W_c(\PP,\QQ)\leq \delta\right\}
% \end{align*}
% A DRO problem is a linear optimization problem over Wasserstein uncertainty sets. We can show that $\mathcal{A}_{\varepsilon}(\PP)$ is actually a Wasserstein uncertainty set for a well-suited cost on $(\XX\times\YY)^2$. For $\varepsilon$, we define $c_\varepsilon$ the cost defined as $c_\varepsilon((x,y),(x',y')) = d(x,x')$ if $d(x,x')\leq\varepsilon$ and $y = y'$, and $+\infty$ otherwise. The cost for perturbations that changing the label and the input by a distance greater than $\varepsilon$ would be infinite. Next proposition link the Wasserstein ball associated with $c_\varepsilon$ and $\mathcal{A}_{\varepsilon}(\PP)$.
% \begin{prop}
% Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\varepsilon>0$ and $\delta>\varepsilon$, then:
% \begin{align*}
%     \mathcal{B}_{c_\varepsilon}(\PP,\delta) =\mathcal{A}_{\varepsilon}(\PP)
% \end{align*}
% \end{prop}
% One may have thought to apply directy Theorem 1 from~\citep{blanchet2019quantifying} to prove Proposition~\ref{prop:dro_adv}; however, the result holds for real-valued costs (i.e. $<\infty$). We believe it can be extended to infinite valued costs, but it is out of the scope of this paper. 
% \begin{prop} 
% \label{prop:dro_adv}
% Let $\PP$ be a Borel probability distribution on $\XX\times\YY$ and $\mu$ a Borel probability distribution on $\Theta$. Let $l:\Theta\times(\XX\times\YY)\to [0,+\infty]$ satisfying Assumption~\ref{ass:loss}. Let $\varepsilon>0$. Then:
% \begin{align*}
% \risk^\epsilon(\mu)= \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x',y')\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x',y'))\right]
% \end{align*}
% \begin{align*}
% \mathbb{E}_{(x,y)\sim \PP}\left[\sup_{\substack{u\in\XX,\\d(x,u)\leq\varepsilon}}l(u,y)\right] = \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x',y')\sim\QQ}\left[\loss(x',y')\right]
% \end{align*}
% The supremum is attained. Moreover $\QQ^*\in \mathcal{A}_{\varepsilon}(\PP)$ is an optimum if and only if there exists $\gamma^*\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right)$ such that: $\Pi_{1\sharp}\gamma^*=\PP$, $\Pi_{2\sharp}\gamma^*=\QQ^*$, $d(x,x')\leq\varepsilon$, $y=y'$ and  $l(x',y')=\sup_{\substack{u\in\XX,d(x,u)\leq\varepsilon}}l(u,y)$ $\gamma^*$-almost surely.
% \end{prop}


% say that the program is linear blabla + link with latest pydi
% One can also recast the adversarial problem as an infinite linear problem:
% \begin{align*}
%   \risk^\epsilon(\mu) = \sup_{\gamma\in \Tilde{\mathcal{A}}_{\varepsilon}(\PP)}\mathbb{E}_{(x,y,x',y')\sim\gamma}\left[\loss(x',y')\right]
% \end{align*}

% where 
% \begin{align*}
% \Tilde{\mathcal{A}}_{\varepsilon}&(\PP) := \left\{\gamma\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right)\mid~\Pi_{1\sharp}\gamma=\PP\right.\\
% &\left.\int \delta\{d(x,x')\leq\varepsilon,~y=y'\}d\gamma(x,y,x'y')=0\right\}
% \end{align*}
% with $\delta$ is the indicator function. Remark that $\mathcal{A}_{\varepsilon}(\PP)=\Pi_{2\sharp}\Tilde{\mathcal{A}}_{\varepsilon}(\PP)$

% \paragraph{A primal-dual formulation of risk minimization.}Let $\mu\in\mathcal{M}^1_+(\Theta)$ a possibly randomized classifier. Thanks to Proposition~\ref{prop:dro_adv}, we have that for $\varepsilon>0$:
% \begin{align*}
%     \risk^\varepsilon(\mu)=\sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right]
% \end{align*}
% Following the definition of the risk minimization objective,  one can define the dual of this problem for randomized classifiers:
% \begin{align}
%     \sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\inf_{\mu\in\mathcal{M}^1_+(\Theta)}\mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right]
% \label{eq:dual_pb}
% \end{align}
% and its analog for deterministic classifiers:
% \begin{align*}
%     \sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\inf_{\theta\in\Theta}\mathbb{E}_{(x,y)\sim\QQ}\left[\loss(\theta,(x,y))\right]
% \end{align*}
% Then, one can notice that the dual problems for deterministic and randomized classifiers are equivalent\footnote{See Appendix XXX for more details}. We denote $\dualvalue^\varepsilon$ the value of the dual problem.
% Weak duality is always satisfied:
% \begin{align}
% \label{eq:weak_duality}
% \dualvalue^\varepsilon\leq \valuerand^\varepsilon\leq \valuedet^\varepsilon
% \end{align}
% We will show in the next section, that, under Assumption~\ref{ass:loss}, strong duality always holds for this min-max problem.


% \begin{definition}[Optimal transport problem] Let $(\mathcal{Z},d)$ be a Polish space. Let $c:\mathcal{Z}^2\rightarrow\mathbb{R}^+\cup\{+\infty\}$ be a lower semi-continuous function. For $\PP,\QQ\in\mathcal{M}^+_1(\mathcal{Z})$, the primal optimal transport problem is defined as:
% \begin{align*}
%   W_c(\PP,\QQ):=\inf_{\gamma\in\Gamma_{\PP,\QQ}}  \int_{\mathcal{Z}^2} c(z,z')d\gamma(z,z')
% \end{align*}
% with $\Gamma_{\PP,\QQ}:=\left\{\gamma\in\mathcal{M}^+_1(\mathcal{Z}^2)\mid~\Pi_{1\sharp}\gamma = \PP,~\Pi_{2\sharp}\gamma = \QQ \right\}$ 
% \end{definition}

% We now define the Wasserstein uncertainty set.
% \begin{definition}[Wasserstein uncertainty set]Let $(\mathcal{Z},d)$ be a Polish space. Let $c:\mathcal{Z}^2\rightarrow\mathbb{R}^+\cup\{+\infty\}$ be a lower semi-continuous function. For $\PP\in\mathcal{M}^+_1(\mathcal{Z})$ and $\delta>0$, we define the Wasserstein uncertainty set:
% \begin{align*}
%     \mathcal{B}_{c}(\PP,\delta) := \left\{\QQ\in \mathcal{M}^+_1(\mathcal{Z})\mid W_c(\PP,\QQ)\leq \delta\right\}
% \end{align*}

% \end{definition}
% We recall that since for all $\PP$, $\QQ\mapsto W_c(\PP,\QQ)$ is convex, the Wasserstein uncertainty sets are convex. Moreover, $\QQ\mapsto W_c(\PP,\QQ)$ is a lower semi-continuous function for the weak topology then $\mathcal{B}_{c}(\PP,\delta)$ is a closed set. Under some mild assumptions the Wasserstein uncertainty balls are compact for weak topology. See details in App. 

% We now connect this problem to that of designing adversarial attacks for a given classification task. Let $(\XX,d_{\XX})$ be a proper Polish metric space representing the input space. Let $\YY=\{1,\dots,K\}$ be the labels set, endowed with trivial metric  $d_{\YY}(y,y') = \mathrm{1}_{y\neq y'}$. Then the space  $(\XX\times\YY,d_\XX\oplus d_\YY)$ is a proper Polish space. We denote $c_\varepsilon$ the cost defined as $c_\varepsilon((x,y),(x',y')) = d(x,x')$ if $d(x,x')\leq\varepsilon$ and $y = y'$, and $+\infty$. The cost for perturbations that changing the label and the input by a distance greater than $\varepsilon$ would be infinite. For $\delta>\epsilon$, next proposition shows that $\mathcal{B}_{c_{\varepsilon}}(\PP,\delta)$ allows all perturbations smaller than $\epsilon$.

% \begin{prop}
% Let $\PP$ be a distribution on $\XX\times\YY$ and $\varepsilon>0$ and $\delta>\varepsilon$, then:
% \begin{align*}
% \mathcal{B}_{c_{\varepsilon}}&(\PP,\delta) = \left\{\QQ\in\mathcal{M}^+_1(\XX\times\YY)\mid\exists \gamma\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right),\right.\\
% &\left.d(x,x')\leq\varepsilon,~y=y'~~ \gamma\text{-a.s.},~\Pi_{1\sharp}\gamma=\PP,~\Pi_{2\sharp}\gamma=\QQ\right\} 
% \end{align*}
% This set will be denoted $\mathcal{A}_\varepsilon(\PP)$ this set. The set $\mathcal{A}_\varepsilon(\PP)$ is a convex and compact for weak topology.
% \end{prop}
 
% \begin{prop} 
% \label{prop:dro_adv}
% Let $\PP$ be a distribution on $\XX\times\YY$. Let $l:\XX\times\YY\mapsto\mathbb{R}$ be an upper semi continuous measurable function. We suppose that $l\in L^1(\PP)$. Let $\varepsilon>0$. Then:
% \begin{align*}
% \mathbb{E}_{(x,y)\sim \PP}\left[\sup_{\substack{u\in\XX,\\d(x,u)\leq\varepsilon}}l(u,y)\right] = \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x',y')\sim\QQ}\left[\loss(x',y')\right]
% \end{align*}
% The supremum is attained. Moreover $\QQ^*\in \mathcal{A}_{\varepsilon}(\PP)$ is an optimum if and only if there exists $\gamma^*\in\mathcal{M}^+_1\left((\XX\times\YY)^2\right)$ such that: $\Pi_{1\sharp}\gamma^*=\PP$, $\Pi_{2\sharp}\gamma^*=\QQ^*$, $d(x,x')\leq\varepsilon$, $y=y'$ and  $l(x',y')=\sup_{\substack{u\in\XX,d(x,u)\leq\varepsilon}}l(u,y)$ $\gamma^*$-almost surely.
% \end{prop}

% \laurent{can we prove this result without using blanchet, i think so no? It is the result of blanchet}

\section{Nash Equilibria in the Adversarial Game}
\label{sec:nash-eq}

\subsection{Adversarial Attacks as a Zero-Sum Game}

Thanks to Proposition~\ref{sec:adv-problem}, the adversarial risk minimization problem can  be seen as a two-player zero-sum game that writes as follows,
\begin{align}
    \inf_{\mu\in\mathcal{M}^1_+(\Theta)} \sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right].
\label{eq:primal_pb}
\end{align}
In this game the classifier objective is to find the best distribution $\mu \in \mathcal{M}_1^+(\Theta)$ while the adversary is manipulating the data distribution. For the classifier, solving the infimum problem in Equation~\eqref{eq:primal_pb} simply amounts to solving the adversarial risk minimization problem -- Problem~\eqref{eq:advriskmin}, whether the classifier is randomized or not. Then, given a randomized classifier $\mu \in \mathcal{M}_1^+(\Theta)$, the goal of the attacker is to find a new data-set distribution $\mathbb{Q}$ in the set of adversarial distributions $\mathcal{A}_{\varepsilon}(\PP)$ that maximizes the risk of $\mu$. More formally, the adversary looks for $$\mathbb{Q} \in \argmaxB_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)} \mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right]. $$
In the game theoretic terminology, $\mathbb{Q}$ is also called the best response of the attacker to the classifier $\mu$.

\begin{rmq}
Note that for a given classifier $\mu$ there always exists a ``deterministic'' best response, i.e. every single point $(x,y)$ is mapped to another single point $T(x,y)$. Let $T:\XX\times\YY\to\XX\times\YY$ be defined such that for all $(x,y)\in\XX\times\YY$, $\EE_{\theta\sim\mu}\left[\loss(T(x,y))\right] = \sup_{x',~d(x,x')\leq\varepsilon}\EE_{\theta\sim\mu}\left[ L(x',y)\right]$. Thanks to~\citep[Proposition 7.50]{bertsekas2004stochastic}, $T$ is $\PP$-measurable. Moreover, we get that $\QQ = (T,id)_\sharp \PP$ belongs to the best response to $\mu$. Therefore, $T$ is the optimal ``deterministic'' attack against the classifier $\mu$.
\end{rmq}


%The classifier cannot play a best response against the attacker since the attacker is usually unknown. Thanks to the inequality~\eqref{eq:weak_duality}, the lowest risk, the classifier can hope is $\mathcal{D}^\varepsilon$. But as seen in the motivating example, it might not been attained by a deterministic classifier. We show in this section, that randomized classifiers can approach $\mathcal{D}^\varepsilon$ arbitrary closely.

%\begin{itemize}
%    \item 3.1 0 sum game , mininmizer = jeu
%    \item in this game: classifier oblivious to the attacker -> standard setting, attacker is whitebox
%    \item 3.2 dual formulation: sup inf, attackant adaptif, and Black box attacks
%    \item 3.3 evaluating duality gap
%\end{itemize}

\subsection{Dual Formulation of the Game}

Every zero sum game has a dual formulation that allows a deeper understanding of the framework. Here, from Proposition~\ref{prop:dro_adv}, we can define the dual problem of adversarial risk minimization for randomized classifiers. This dual problem also characterizes a two-player zero-sum game that writes as follows,
\begin{align}
    \sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\inf_{\mu\in\mathcal{M}^1_+(\Theta)}\mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right].
\label{eq:dual_pb}
\end{align}
In this dual game problem, the adversary plays first and seeks an adversarial distribution that has the highest possible risk when faced with an arbitrary classifier. This means that it has to select an adversarial perturbation for every input $x$, without seeing the classifier first. In this case, as pointed out by the motivating example in Section~\ref{sec:motiv-ex}, the attack can (and should) be randomized to ensure maximal harm against several classifiers. Then, given an adversarial distribution, the classifier objective is to find the best possible classifier on this distribution. Let us denote $\dualvalue^\varepsilon$ the value of the dual problem. Since the weak duality is always satisfied, we get
\begin{align}
\label{eq:weak_duality}
\dualvalue_\varepsilon\leq \valuerand_\varepsilon\leq \valuedet_\varepsilon.
\end{align}
Inequalities in Equation~\eqref{eq:weak_duality} mean that the lowest risk the classifier can get (regardless of the game we look at) is $\mathcal{D}^\varepsilon$. In particular, this means that the primal version of the game, \emph{i.e.} the adversarial risk minimization problem, will always have a value greater or equal to $\mathcal{D}^\varepsilon$. As we discussed in Section~\ref{sec:motiv-ex}, this lower bound may not be attained by a deterministic classifier. As we will demonstrate in the next section, optimizing over randomized classifiers allows to approach $\mathcal{D}^\varepsilon$ arbitrary closely.

Note that, we can always define the dual problem when the classifier is deterministic, \begin{align*}
    \sup_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)}\inf_{\theta\in\Theta}\mathbb{E}_{(x,y)\sim\QQ}\left[\loss(\theta,(x,y))\right].
\end{align*}


We can deduce an immediate corollary from Proposition~\ref{prop:eqstandardrisk}
that the dual problems for deterministic and randomized classifiers have the same value.
\begin{corollary}
Under Assumption~\ref{ass:loss}, the dual for randomized and deterministic classifiers are equal.
\end{corollary}


%This primal-dual formulation highlights the profound link between  game theory and adversarial examples. Indeed, the adversarial risk minimization can be seen as a zero-sum game. In this section we study the Nash equilibrium of this game in the randomized setting. \textcolor{red}{pas tres clair, en quoi c'est la formulation dual qui fait apparaitre le jeu?} %We show in the next section, that, under Assumption~\ref{ass:loss}, strong duality always holds for this min-max problem, and hence study the Nash equilibrium of the related game.
%We now define the adversarial examples game, as a zero-sum game, where one player is the attacker and the other is the classifier. We study the Nash equilibria of this game in both randomized and deterministic cases.




%\textbf{Attacker Objective.}
%Given a possibly  randomized classifier $\mu\in \mathcal{M}^1_+(\Theta)$, the goal of the attacker is to find a possibly random perturbation for each single pair $(x,y)\in \supp(\PP)$, such that this perturbation maximizes $\mathbb{E}_{\theta\sim\mu}[\loss(\theta,(x',y))]$ over $x'$ under the constraint that $d(x,x')\leq\varepsilon$. In other words, thanks to Proposition $1$, the set of best responses to $\mu$ writes
%\begin{align*}
%    \text{BR}(\mu) := \argmaxB_{\QQ\in\mathcal{A}_{\varepsilon}(\PP)} \mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[ l(\theta,(x,y))\right] 
%\end{align*}




%In a white-box setting, the adversary knows the classifier $\mu$ before attacking then he only needs to perform a best response. In the black-box setting, it is different: since the adversary does not know the classifier $\mu$, he needs to compute a solution to the sup-inf problem to get its attack the most effective. Note that in this case, the attack can be possibly random: a single point $x$ can be mapped to a distribution of attacks.



%\textbf{Classifier Objective.} In the standard adversarial examples setting, since the attacker plays after the classifier, the goal of the classifier is to find the best classifier against every possible attacks at level $\varepsilon$, i.e. solving the adversarial risk minimization problem~\eqref{eq:advriskmin}, whether the classifier is randomized or not. The classifier cannot play a best response against the attacker since the attacker is usually unknown. Thanks to the inequality~\eqref{eq:weak_duality}, the lowest risk, the classifier can hope is $\mathcal{D}^\varepsilon$. But as seen in the motivating example, it might not been attained by a deterministic classifier. We show in this section, that randomized classifiers can approach $\mathcal{D}^\varepsilon$ arbitrary closely.

\subsection{Nash Equilibria for Randomized Strategies}

In the adversarial examples game, a Nash equilibrium is a couple $(\mu^*,\QQ^*)\in\mathcal{M}^1_+(\Theta)\times\mathcal{A}_\varepsilon(\PP)$ where both the classifier and the attacker have no incentive to deviate unilaterally from their strategies $\mu^*$ and $\QQ^*$. More formally, $(\mu^*,\QQ^*)$ is a Nash equilibrium of the adversarial examples game if $(\mu^*,\QQ^*)$ is a saddle point of the objective function $$(\mu,\QQ)\mapsto \mathbb{E}_{(x,y)\sim\QQ,\theta\sim\mu}\left[\loss(\theta,(x,y))\right].$$ Alternatively, we can say that $(\mu^*,\QQ^*)$ is a Nash equilibrium if and only if $\mu^*$ solves the adversarial risk minimization problem -- Problem~\eqref{eq:advriskmin}, $\QQ^*$ the dual problem -- Problem~\eqref{eq:duality}, and $\mathcal{D}^\varepsilon=\mathcal{V}_{rand}^\varepsilon$. In our problem, $\QQ^*$ always exists but it might not be the case for $\mu^*$. Then for any $\delta>0$, we say that  $(\mu_\delta,\QQ^*)$ is a $\delta$-approximate Nash equilibrium if $\QQ^*$ solves the dual problem and $\mu_\delta$ satisfies $\mathcal{D}^\varepsilon\geq\risk_\varepsilon(\mu_\delta)-\delta$. 
% \begin{align*}
%     \text{BR}(\QQ) := \argmaxB_{\mu\in\mathcal{A}_{\varepsilon}(\PP)} \int l(\theta,(x,y))d\QQ(x,y)d\mu(\theta)
% \end{align*}

% \begin{align*}
%     \inf_{\theta\in\Theta} \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP))} \mathbb{E}_{z\sim\QQ }\left[\loss(\theta,z)\right]:=\int l(\theta,z)d\QQ(z)
% \end{align*}
% where: 
% \begin{align*}
%     \mathcal{A}_{\varepsilon}(\PP)) := \left\{\QQ\in \mathcal{M}^+_1(\mathcal{Z})\text{ s.t. } D(\PP,\QQ)\leq \varepsilon\right\}
% \end{align*}

% We will study:

% \begin{align*}
%     \inf_{\mu\in \mathcal{M}^+_1(\Theta)} \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP))} \mathbb{E}_{\theta \sim \mu, z\sim\QQ }\left[\loss(\theta,z)\right] \\
%     =\int l(\theta,z)d\mu(\theta)d\QQ(z):=L(\mu,\QQ)
% \end{align*}

%Meyer{generalise to any sub convex set of the set of distributions of $\Theta$}

We now state our main result: the existence of approximate Nash equilibria in the adversarial examples game when both the classifier and the adversary can use randomized strategies. More precisely, we demonstrate that the duality gap between the adversary and the classifier problems is zero, which gives as a corollary the existence of Nash equilibria. 

\begin{thm}
\label{thm:duality-rand}
Let $\PP\in\mathcal{M}^1_+(\XX\times\YY)$. Let $\varepsilon>0$. Let $\loss:\Theta\times(\XX\times\YY)\to [0,\infty)$ satisfying Assumption~\ref{ass:loss}. %Let assume that for all $\mu\in\mathcal{M}^1_+(\Theta)$ and $(x,y)\in\XX\times\YY$, $l(\cdot,(x,y))$ is $\mu$-measurable.
Then strong duality always holds in the randomized  setting:
\begin{align}
 \label{eq:duality}\inf_{\mu\in \mathcal{M}^+_1(\Theta)} \max_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)} \mathbb{E}_{\theta \sim \mu, (x,y)\sim\QQ }\left[\loss(\theta,(x,y))\right]\\
=
\nonumber\max_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\inf_{\mu\in \mathcal{M}^+_1(\Theta)}  \mathbb{E}_{\theta \sim \mu, (x,y)\sim\QQ }\left[\loss(\theta,(x,y))\right]
\end{align}
The supremum is always attained. If $\Theta$ is a compact set, and for all $(x,y)\in\XX\times\YY$, $\loss(\cdot,(x,y))$ is lower semi-continuous, the infimum is also attained.
\end{thm}


\begin{proof}
$\mathcal{A}_\varepsilon(\PP)$, endowed with the weak topology of measures, is a Hausdorff compact convex space, thanks to Proposition~\ref{prop:wass_ball}. Moreover, $\mathcal{M}^1_+(\Theta)$ is clearly convex and $(\QQ,\mu)\mapsto \int ld\mu d\QQ$ is bilinear, hence concave-convex. Moreover thanks to Lemma~\ref{lem:usc2}, for all $\mu$, $\QQ\mapsto \int ld\mu d\QQ$ is upper semi-continuous. Then Fan's theorem applies and strong duality holds.
\end{proof}
 \begin{corollary}
\label{cor:nash-eq}
Under Assumption~\ref{ass:loss}, for any $\delta>0$, there exists a $\delta$-approximate Nash-Equibilrium $(\mu_\delta,\QQ^*)$. Moreover, if the infimum is attained, there exists a Nash equilibrium $(\mu^*,\QQ^*)$ to the adversarial examples game.
\end{corollary}



\cite{bose2021adversarial} mentioned a particular form of Theorem~\ref{thm:duality-rand} for convex cases.  It is still a direct corollary of Fan's theorem. This theorem can be stated as follows: 
\begin{thm}Let $\PP\in\mathcal{M}^1_+(\XX\times\YY)$, $\varepsilon>0$ and $\Theta$ a convex set. Let $\loss$ be a loss satisfying Assumption~\ref{ass:loss}, and also, $(x,y)\in\XX\times\YY$, $\loss(\cdot,(x,y))$ is a convex function, then we have the following:
\begin{align*}
\inf_{\theta\in\Theta} \sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)} \mathbb{E}_{ \QQ }\left[\loss(\theta,(x,y))\right]
=
\sup_{\QQ\in \mathcal{A}_{\varepsilon}(\PP)}\inf_{\theta\in \Theta}  \mathbb{E}_{\QQ }\left[\loss(\theta,(x,y))\right]
\end{align*}
The supremum is always attained. If $\Theta$ is a compact set then, the infimum is also attained.
\end{thm}


Theorem~\ref{thm:duality-rand} shows that $\mathcal{D}^\varepsilon=\mathcal{V}_{rand}^\varepsilon$. From a game theoretic perspective, this means that the minimal adversarial risk for a randomized classifier against any attack (primal problem) is the same as the maximal risk an adversary can get by using an attack strategy that is oblivious to the classifier it faces (dual problem). This suggests that playing randomized strategies for the classifier could substantially improve robustness to adversarial examples.
%Second, Corollary~\ref{cor:nash-eq} says that there always exists a randomized classifier that gets arbitrarily close this minimal adversarial risk. Hence, if we can design an algorithm that efficiently learn this classifier, we will get improve adversarial robustness over classical deterministic defenses. 
In the next section, we will design an algorithm that efficiently learn a randomized classifier and show improved adversarial robustness over classical deterministic defenses.


\begin{rmq}
Theorem~\ref{thm:duality-rand} remains true if one replaces $\mathcal{A}_\varepsilon(\PP)$ with any other Wasserstein compact uncertainty sets (see~\citep{yue2020linear} for conditions of compactness). 
\end{rmq}

%Meyer{Add discrete case also}
% \paragraph{Case of $0/1$ loss.} The $0/1$ loss is particularly interesting in adversarial attacks since in this case the goal of the attacker would be to maximize the probability of misclassification. We can prove that our duality result also holds for the $0/1$ loss. 

% For $\theta\in\Theta$, we define $f_\theta:x\in\XX\mapsto (f_\theta(x)_1,\dots,f_\theta(x)_K)\in\mathbb{R}^K$ such that the predicted class is $y\in\YY$ if and only if: $f_\theta(x)_y>\max_{i\neq y} f_\theta(x)_i$. The corresponding $0/1$ loss is then: 
% \begin{align*}
% l(\theta,(x,y))=\mathbf{1}_{f_\theta(x)_y\leq\max_{i\neq y} f_\theta(x)_i}
% \end{align*}

% Assuming that for all $\theta$, $f_\theta(\cdot)$ is continuous, and that for all $\mu\in\mathcal{M}^1_+(\Theta)$ and $(x,y)\in\XX\times\YY$, $l(\cdot,(x,y))$ is $\mu$-measurable (for instance, for all $x\in\XX$, $f_{\cdot}(x)$ is continuous),  then the duality result~\eqref{eq:duality} holds for the $0/1$ loss. However the existence of a minimizing distribution $\mu^*\in\mathcal{M}^1_+(\Theta)$ is not guaranteed. See Appendix XXX for more details.
% \begin{prop}Let $\lambda>0$. For all $\theta\in \Theta$, $f_\theta:\XX\mapsto \mathbb{R}^k$. be classifier 
% \begin{align*}
% \sigma_\lambda(\theta,(x,y)) =\left(1+\exp\left\{-\lambda\left(f_\theta^y(x)-\max_{i\neq y}f_\theta^i(x)\right)\right\}\right)^{-1}
% \end{align*}
% \end{prop}






% \paragraph{Example where randomization is needed}Let now exhibit a simple example where randomization is needed. We assume that $\XX = \mathbb{R}$ and $\YY=\{-1,1\}$. Let assume the following distribution $\PP$: $Y = 1$ with probability $1/2$ and $-1$ with probability $1/2$. Conditionally to $Y=1$, $X$ always equals $0$ and conditionally to $Y=-1$, $X=1$ with probability $1/2$ and $-1$ otherwise.

% We assume that $d_\XX(x,x') =\lvert x-x'\rvert$. We now fix $\varepsilon=1$. Let consider the $0/1$ loss: $l(f,(x,y)) =\mathbf{1}_{f(x)\neq y}$.

% In this example, every Bayes optimal classifier have a zero natural risk, but the its adversarial risk is actually equal to $1$. Let now reduce the hypothesis class to two classifiers: $f_1(x) = \sign\left\{x\leq 1/2\right\}$ and $f_2(x) = \sign\left\{x\geq -1/2\right\}$. Then for $i=1,2$, $\risk(f_i)=1/4$ and $\risk(f_i)=3/4$. Let now define the randomized classifier $f=f_1$ with probability $1/2$ and $f_2$ with probability $1/2$. In this case we have $\risk(f)=1/4$ and $\risk(f)=1/2$.


% \section{todo}
% \begin{itemize}

%     \item unicity of Nash equilbrium?  no a priori
%     \item statistical study of the nash equilibrium
%     \item big part: algo...
% \end{itemize}


