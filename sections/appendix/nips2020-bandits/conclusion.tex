\section{Conclusion}
We presented several settings for online attacks on contextual bandits.
We showed that an attacker can force any contextual bandit algorithm to almost always pull an arbitrary target arm $a^{\dagger}$ with only sublinear modifications of the rewards. When the attacker can only modify the contexts, we prove that \linucb can still be attacked and made to almost always pull an arm in $A^{\dagger}$ by adding sublinear perturbations to the contexts. 
When the attacker can only attack a single context, we derive a feasibility condition for the attacks and we introduce a method to compute some attacks of small instantaneous cost for \linucb, \epsgreedy and \lints.
To the best of our knowledge, this paper is the first to describe effective attacks on the contexts of contextual bandit algorithms. Our numerical experiments, conducted on both synthetic and real-world data, validate our results and show that the attacks on all contexts are actually effective on several algorithms and with more permissible settings. 



