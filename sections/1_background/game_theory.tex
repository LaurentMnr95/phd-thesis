\section{Game Theory in a Nutshell}

Game theory studies strategic interactions among agents assuming their actions are rational. It has many applications in social science~\citep{xxx} or machine learning~\citep{goodfellow2014generative} for instance. In this small section, we recall main concepts in game theory that will help us understanding better the problem of adversarial examples. 


\subsection{Two-player zero-sum games}

An important subclass of game theoretic problems are two-person zero-sum games.  In such a game there are two players namely Player 1 and Player 2 with opposite objectives. When Player 1 plays an action $x$ in some space $\mathcal{A}_1$ and Player 2 players an action $y$in some space $\mathcal{A}_2$, Player 1 receives a reward $u_1(x,y)$ (also named utility) and Player 2 receives a reward $u_2(x,y)= -u_1(x,y)$. The objective for each player is to find what is the best strategy to play against the other player to maximize their utility. These strategies are of two types:
\begin{itemize}
    \item \textbf{deterministic strategies:} the player plays a strategy $x$ (for Player 1) or $y$ (for Player 2). 
    \item \textbf{mixed strategies:} the player pick up $x$ (for Player 1) or $y$ (for Player 2) randomly according to some probability distribution $\mu$. In this case, the utility functions are averaged according to the strategies $\mu$ and $\nu$ for respectively Player 1 and Player 2.  The average reward of the Player 1 is then $\mathbb{E}_{x\sim\mu,y\sim\nu}\left[u_1(x,y)\right]$.
\end{itemize}

An important matter is the order of play in the game: the strategies might be different if the player know what was the action of the player before him. This leads us to the notion of best response. Assume that a mixed strategy $\mu$ was played by Player 1, then the set of best responses for Player 2 to Player 1 strategy is a strategy that maximizes the utility: $\arg\max_{\nu}\mathbb{E}_{x\sim\mu,y\sim\nu}\left[u_1(x,y)\right]$. We denote this set $BR_2(\mu)$. Game theory aims at studying and computing the nature of strategies in response to other players strategies.

\subsection{Equilibria in two-player zero-sum games}



In game theory, optimal strategies for players are studied under the name of equilibria. Depending on the game, we might have interest in two types of equilibria: Nash equilibria where players do not cooperate and have to choose a strategy simultaneously, and Stackelberg equilibria where a player defines its strategy before the other one. We only focus on two-player zero-sum game.

\paragraph{Nash Equilbria.} In a Nash equilibrium, each player is assumed to know the equilibrium strategies of the othe player, and no player has anything to gain by changing only their own strategy. In other words, it is the strategy a rational player should adopt without any cooperation with the other. Note that the existence of Nash equilibrium is not always guarantees. We are going to formalize mathematically the meaning of a Nash equilibrium. A Nash equilibrium is a tuple of actions $(x^\star,y^\star)$ for Players 1 and 2 such that for all other actions $x$ for Player 1 and $y$ for Player 2 we have:
\begin{align*}
    u_1(x^\star,y^\star)\geq u_1(x,y^\star)\text{ and } u_2(x^\star,y^\star)\geq u_2(x^\star,y)
\end{align*}
Note that here the strategies can be either mixed or deterministic. In a two-player zero-sum game we can restate the previous condition as 
\begin{align*}
    u_1(x,y^\star)\leq u_1(x^\star,y^\star)\leq u_1(x^\star,y)
\end{align*}
We remark that a Nash equilbrium is defined as a best response to each other strategy, i.e. $(x^\star,y^\star)$ is a Nash equilibrium if and only if $x^\star\in BR_1(y^\star)$ and $y^\star\in BR_2(x^\star)$. We can then come to a necessary and sufficient condition for the existence of Nash equilibria in the case of a two-player zero-sum game:
\begin{align*}
    \max_x\min_y u_1(x,y) = \min_y\max_x u_1(x,y)
\end{align*}
It is a strong duality condition on the function $u_1$, with the additional property that the optima are attained. In there is duality but the optima are attained, we can state the existence of $\delta$-approximate Nash equilbria for every $\delta>0$, i.e. $(x^\delta,y^\delta)$ such that:
\begin{align*}
    u_1(x^\delta,y^\delta)\geq u_1(x,y^\delta)-\delta\text{ and } u_2(x^\delta,y^\delta)\geq u_2(x^\delta,y)-\delta
\end{align*}


\paragraph{Stackelberg Equilibria.} A Stackelberg game is a game where Player 1 defines its strategy before Player 2. Stackelberg equilibria are a tuple of optimal strategies for each player. As Player 1 needs to define its strategy before Player 2, the strategy $x^\star$ of Player 1 has to maximize $\min_y u_1(x,y)$. The strategy for Player 2 is then just to play an action that maximizes its utility given that Player 1 played $x^\star$. In other words, he has to choose a best response to $x^\star$. Note that if $(x^\star,y^\star)$ is a Nash equilibrium then it is also a Stackelberg equilibrium.


\paragraph{Computing Equilibria.} The computation of Nash or Stackelberg equilbria highly depends on the setting of the game. For instance, the players might have or not knowledge of the other strategy or utility functions. In finite case settings there have been a large  TODO

For instance, under complete knowledge of utilities and strategies, vanilla optimization problems 

\subsection{Strong Duality Theorems}

\paragraph{Finite action sets.} In a two-player zero-sum game where the actions space is finite for both players, the rewards can be casted in a matrix $A\in R^{n\times m}$ where $A_{ij} =u_1(x_i,y_j)$. In this case, Von Neumann~\ref{von} proved that there always exists a mixed equilibrium. A mixed strategy of $n$ actions can be embedded in the probability simplex:
\begin{align*}
    \Delta_n := \left\{(p_1,\dots,p_n)\in\RR_+^n| \sum_{i=1}^n p_i = 1  \right\}
\end{align*}

\begin{thm}[Von Neumann's Theorem]
    Let $A\in R^{n\times m}$ then:
    \begin{align*}
        \max_{x\in \Delta_n}\min_{y\in \Delta_m} x^TAy = \min_{y\in \Delta_m}\max_{x\in \Delta_n} x^TAy
    \end{align*}
\end{thm}

\paragraph{Infinite action sets.} For infinite action sets, Von Neumann's Theorem is usually not sufficient. There are two main extensions with different hypothesis, namely Sion's Theorem and Fan's Theorem.

\begin{thm}[Sion's Theorem]
Let $X$ be a compact convex set and $Y$ be a convex set of a linear topological space. Let $u:X\times Y\to\RR$ be a function such that for all $y\in Y$, $u(\cdot,y)$ is quasi-concave and upper semi-continuous; and for all $x\in X$, $u(x,\cdot)$ is quasi-convex and lower semi-continuous, then:
\begin{align*}
    \max_{x\in X}\inf_{y\in Y} u(x,y) = \inf_{y\in Y}\max_{x\in X} u(x,y)
\end{align*}
Moreover, if $Y$ is compact, the infimum is attained.
\end{thm}



\begin{thm}[Fan's Theorem]
Let $X$ be a compact convex set and $Y$ be a convex set (not necessarily topological). Let $u:X\times Y\to\RR$ be a function such that for all $y\in Y$, $u(\cdot,y)$ is concave and upper semi-continuous; and for all $x\in X$, $u(x,\cdot)$ is convex, then:
\begin{align*}
    \max_{x\in X}\inf_{y\in Y} u(x,y) = \inf_{y\in Y}\max_{x\in X} u(x,y)
\end{align*}
Moreover, if $Y$ is compact and for all $x\in X$, $u(x,\cdot)$ is lower semi-continuous, the infimum is attained.
\end{thm}

The hypothesis are close since both concerns convexity or quasi convexity of the reward function and the semi-continuity of the partial reward. The differences are subtle and there are cases where one may use either Sion's or Fan's Theorem. For infinite action sets, it is usual to consider mixed strategies as probability distributions on $X$ or $Y$. In this case, we often endow $\mathcal{M}^1_+(\XX)$ and $\mathcal{M}^1_+(\YY)$ with the weak-$*$ topology of measures and use Sion's or Fan's Theorem directly on these probability spaces.

\subsection{Computation of Nash Equilibria}

TODO



% when $u_1$ is concave in $x$ and convex in $y$ as Von-Neumann's Theorem, Sion's Theorem or Fan's Theorem. In particular, in a two-player zero-sum game where the actions space is finite for both players, there always exists a mixed equilibrium.
% For infinite spaces, the questions of existence of Nash equilibrium is more difficult and need to be treated case by case.
