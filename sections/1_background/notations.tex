\section{Classification}
First, we formalize the classification task:
\begin{itemize}
    \item Consider an input space $\mathcal{X}$, typically images. We assume this space is endowed an arbitrary metric $d$ possibly the perception distance or any $\ell_p$ norm. In the remaining of the manuscript, unless it is specified, $(\mathcal{X},d)$ will be a \textit{proper} (i.e. closed balls are compact) \textit{Polish} (i.e. completely separable) metric space. Note that for any norm $\lVert\cdot\rVert$,  $(\mathbb{R}^d,\lVert\cdot\rVert)$ is a proper Polish metric space.
    \item Each image $x\in \mathcal{X}$ has to be classified to a label $y$. We describe the set of labels $\mathcal{Y}:=\{1,\dots,K\}$ as descriptors of an input. For instance the label of an image will be the description of it. $\mathcal{Y}$ will be endowed with the trivial metric  $d'(y,y') = \mathbf{1}_{y\neq y'}$. Note that $(\mathcal{X}\times\mathcal{Y},d\oplus d')$ is a proper Polish space.
\end{itemize}
With such spaces, the space $(\mathcal{X}\times\mathcal{Y},d\oplus d')$ is also a proper Polish space. As in every classification problem, the data is sampled from probability distribution $\PP$. We will assume from now that the distribution we consider are Borel. For any Polish Space $\mathcal{Z}$, we will denot $\mathcal{B}(\mathcal{Z})$ the Borel $\sigma$-algebra and the set of Borel distributions $\mathcal{Z}$ over will be denoted $\mathcal{M}_+^1(\mathcal{Z})$. We also recall the notion of \textit{universal measurability}: a set $A\subset \mathcal{Z}$ is said to be universally measurable if it measurable for every \textit{complete} Borel probability measures.

In standard classification, we aim at learning a (universally or Borel) measurable function $h:\mathcal{X}\to\mathcal{Y}$ minimizing the $0/1$ loss risk:
\begin{align}
   \risk_{0/1}(h):=\PP(h(x)\neq y) = \EE_{(x,y)\sim\PP}\left[\mathbf{1}_{h(x)\neq y}\right]
\end{align}
Note that this quantity is well defined when $h$ is measurable. The optimal classifier is called the Bayes Optimal classifier and is defined as $h(x) = \argmaxB_k\PP(y=k\mid x)$. One can note, using disintegration theorem that $h$ is indeed Borel measurable.

However in practice, the access to the Bayes Optimal classifier is impossible because it requires full knowledge on the probability distribution $\PP$ which is not the case in general. Let assume having access to a training set of $n$ data points $\{(x_1,y_1),\dots,(x_n,y_n)\}$. The knowledge of the Bayes classifier on training points would not be sufficient to have generalization properties for the classifier on out-of-sample data points because such functions would overfit the training set. Hence one need to reduce the search space of measurable functions to a much smaller one, we will denote $\mathcal{H}$. More precisely, for binary classification (i.e $\mathcal{Y}:=\{-1,+1\})$, we aim at learning a function $\mathbf{f}:\XX\to\mathbb{R}$ such that $h(x)=\sign(f(x))$ (with a convention on $sign(0)$). In multilabel classification (i.e $|\mathcal{Y}|\geq2$), we learn a function $\mathbf{f}:\XX\to\mathbb{R}^K$ and $h$ is set to $h(x)=\argmaxB_k f_k(x)$. Minimizing directly the $0/1$ loss risk is a NP-hard problem in general CITE. Then one needs to minimize a well-chosen loss function $L$. A \textit{loss function} $L:\mathbb{R}^K\times\mathcal{Y}\to\mathbb{R}$ will be without loss of generality a non negative Borel measurable function. An example of such a loss is the cross entropy loss defined as:
\begin{align*}
    L(\mathbf{f}(x),y)=\sum_{i=1}^n
\end{align*}

The study of which loss is suited for classification has been a widely studied topic. Hence the learning objective is then defined as:

\begin{align*}
\inf_{\mathbf{f}\in\mathcal{H}}\riskemp_{n}(\mathbf{f}):= \frac{1}{n}\sum_{i=1}^nL(\mathbf{f}(x_i),y_i).
\end{align*}

define 


% Instead, we aim at learning either a classifier $h\in\mathcal{H}$ such that:



\section{Background in adversarial classification}
Adversarial classification, we aim at learning a a (universally or Borel) measurable function $h:\mathcal{X}\to\mathcal{Y}$ minimizing the $0/1$ loss risk: 
\begin{align*}
\risk^\varepsilon_{0/1}(h)&:=\PP_{(x,y)}(\exists x'\in\XX\text{ s.t. } d(x,x')\leq \varepsilon \text{ and } h(x')\neq y)\\
&= \EE_{(x,y)\sim\PP}\left[\sup_{x'\in\XX\text{ s.t. } d(x,x')\leq \varepsilon}\mathbf{1}_{h(x')\neq y}\right]
\end{align*}
The definition of this quantity is not immediate and requires a proposition.

\begin{prop}
For any $h$ Borel measurable, the adversarial risk is well defined $\risk^\varepsilon_{0/1}(h)$.
\end{prop}

The existence of a minimizer for adversarial risk is a difficult question, that was partially answered in CITE, which states, under some mild conditions, that the minimum is attained over the set of universally measurable functions.


 define general adversarial loss.



The question of the loss function 


\subsection{Standard datasets in Classification}
Images are embedding in pixels laying in $[0,255]$ and then normalized to $[0,1]$. These images can be black and white, hence encoded on only one channel, or colorful and then encoded on three channels, often, Red, Green, Blue (RGB). The images are of diverse qualities, the number of pixels quantifies this quality.  In image classification evaluation, three datasets are mainly used:
\begin{itemize}
    \item \textbf{MNIST~\citep{lecun1998mnist}:} A dataset of black and white low-quality images representing the $10$ digits. The training set contains $50000$ images and test set $10000$ images. These images are of dimension $28\times28\times 1$ ($784$ in total). This dataset is known to be easy ($>99\%$ can be obtained using simple classifiers). In adversarial classification, the problem is also easy to be solved. Evaluation MNIST is not sufficient to assess the performance of a classifier or even a defense against adversarial examples.
    \item \textbf{CIFAR10 and CIFAR100~\citep{krizhevsky2009learning}:} Datasets of colored low-quality images representing the $10$ labels and $100$ labels for respectively CIFAR10 and CIFAR100. Each training set contains $50000$ images and test set $10000$ images. These images are of dimension $32\times32\times 1$ ($3072$ in total). The current state-of-the-art on CIFAR10 in standard classification is $>99\%$ of accuracy, but asks advanced methods to reach such a score. On CIFAR100, the current state-of-the-art is around $94\%$. In adversarial classification both datasets are challenging and difficult. The evolution of state-of-the-art in adversarial classification is available in RobustBench\footnote{\url{https://robustbench.github.io/}}. Benchmark in adversarial classification are often made on these datasets.
    \item \textbf{ImageNet~\citep{imagenet_cvpr09}:} ImageNet refers to a dataset containing $1.2$ million of images labeled into $1000$ classes. Images are of diverse qualities, but often $224\times224\times 3$ (dimension $150528$ in total). The current state-of-the-art on ImageNet is about $87\%$. There is no need to say that adversarial classification on ImageNet is still a very-challenging task. Further than the standard dataset, ImageNet project is still in development: the project gathers $14197122$ images and $21841$ labels on August 31th, 2021.   


\end{itemize}
\section{Background on adversarial examples}
\subsection{Crafting adversarial examples}

What is the more striking about adversarial examples is the facility to craft them. Let consider an attacker that aim  finding an adversarial perturbation $x'$ of an input $x$ for a given classifier $\mathbf{f}$.  Given a differentiable loss $L$, typically the cross-entropy, the attacker usually maximize the following objective:

\begin{align}
    \max_{x'\in\XX\text{ s.t. } d(x,x')\leq \varepsilon}L\left(\mathbf{f}(x'), y)\right).
\end{align}
To do so, many attacks were proposed that we will categorize in two parts: 
\begin{itemize}
    \item \textbf{White box attacks:} the attacker have the full knowledge of the function $\mathbf{f}$ and its parameters. Hence this attacks are often based on the gradient of the former objective. The most popular white box attacks are CITE
    \item \textbf{Black box attacks:} the attacker have no knowledge on the classifier parameters. The attacker have limited access to the classifier, e.g. he can only access logits or predicted class for instance.
    
\end{itemize}

\subsection{Which Perception Distance to Use?}

The choice of the 
% \section{Optimal Transportation}

% As seen Optimal Transportation seems to play a central role in understanding adversarial attacks, 
% For any Polish space $\mathcal{Z}$, we denote $\mathcal{M}_+^1(\mathcal{Z})$ the Polish space of Borel probability measures on $\mathcal{Z}$. Let us assume the data is drawn from $\PP\in\mathcal{M}_+^1(\mathcal{X}\times\mathcal{Y})$. Let $(\Theta,d_\Theta)$ be a Polish space (not necessarily proper) representing the set of classifier parameters (for instance neural networks). We also define a loss function: $l:\Theta\times (\mathcal{X}\times\mathcal{Y})\to [0,\infty)$ satisfying the following set of assumptions.